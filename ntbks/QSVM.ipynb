{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58fcc23c-8e4c-49c3-ae99-65c9d89b1740",
   "metadata": {},
   "source": [
    "# Task 3: Quantum SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b3915-50bd-48db-acc5-77479cab55bf",
   "metadata": {},
   "source": [
    "We have the following task description for **Task 3** from [Cohort 7 Screening Tasks](https://docs.google.com/document/d/1KBot_q-CQ7FSmAXK45PDHNu8VKedOEbh/edit):\n",
    "\n",
    "Generate a Quantum Support Vector Machine (QSVM) using the [iris dataset](https://archive.ics.uci.edu/ml/datasets/iris) and try to propose a kernel from a parametric quantum circuit to classify the three classes (setosa, versicolor, virginica) using the one-vs-all format, the kernel only works as binary classification. Identify the proposal with the lowest number of qubits and depth to obtain higher accuracy. You can use the UU† format or using the [Swap-Test](https://en.wikipedia.org/wiki/Swap_test)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab83578-2ea3-4460-8a46-a7a0a469727c",
   "metadata": {},
   "source": [
    "## 0. Dependencies and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9483119f-affd-4dbf-9406-d9d3a5987c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn==1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f612a2d2-5b49-4d7c-9e3a-6652c44c0196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/qosf/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane.templates import AngleEmbedding, StronglyEntanglingLayers\n",
    "from pennylane.operation import Tensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(230306)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf47f2c-9e51-4825-9ada-e3e8038da53b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "007d1465-b3b1-405f-a1b7-0008b632b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb5a06d-4129-417a-9195-edd9e8cdaec4",
   "metadata": {},
   "source": [
    "The iris dataset consists of 4 numeric features and the target class:\n",
    "\n",
    "* sepal length (cm)\n",
    "* sepal width (cm)\n",
    "* petal length (cm)\n",
    "* petal width (cm)\n",
    "* **class** (one of `'setosa'=0`, `'versicolor'=1`, `'virginica'=2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e37976-aac9-4ae9-a89e-6b89efc64a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f79f101-6f7b-435f-8a0c-6c0807615450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c534a7b-ae99-4e33-9192-bb5efab774fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class_dict = {\"setosa\": 0, \"versicolor\": 1, \"virginica\": 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f9ac9c-56af-4e91-8e30-e828120d1037",
   "metadata": {},
   "source": [
    "## 2. Preprocess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d7ea14-4bbf-423e-96a8-dd9155fef0cb",
   "metadata": {},
   "source": [
    "Before the training step, we scale both `X` and `y` so that it is accommodated better by the algorithms we use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9e05958-2b6a-4d64-9914-0e891e0aa384",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f8e314b-c6c8-4faf-b484-c8b68b013682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90068117,  1.01900435, -1.34022653, -1.3154443 ],\n",
       "       [-1.14301691, -0.13197948, -1.34022653, -1.3154443 ],\n",
       "       [-1.38535265,  0.32841405, -1.39706395, -1.3154443 ],\n",
       "       [-1.50652052,  0.09821729, -1.2833891 , -1.3154443 ],\n",
       "       [-1.02184904,  1.24920112, -1.34022653, -1.3154443 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321489f-0271-45b4-9919-74aee7865cab",
   "metadata": {},
   "source": [
    "We scale the labels to $[-1,  1]$ for better performance with the SVM algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99c93be7-0b4c-416c-8018-263c0c3bfb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaled = y - 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2d47a-7547-4368-a4ce-b97a2d7dc452",
   "metadata": {},
   "source": [
    "For one-vs-all approach, we set the target class to 1 and the rest to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db10815f-7c77-447e-821a-594968207762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def y_transform(y, target_class):\n",
    "#     y_return = y.copy()\n",
    "#     y_return[y_return != target_class] = 0\n",
    "#     y_return[y_return != 0] = 1\n",
    "#     return y_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b2cf20-c046-4a5c-b1e7-811ef722e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_setosa = y_transform(y, y_class_dict[\"setosa\"])\n",
    "# assert y[y == y_class_dict[\"setosa\"]].sum() == y_setosa.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3c7daa-6aa8-4418-a652-0842e4e7eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_versicolor = y_transform(y, y_class_dict[\"versicolor\"])\n",
    "# assert y[y == y_class_dict[\"versicolor\"]].sum() == y_versicolor.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc7161a-6294-404d-bf13-b712bf1547c5",
   "metadata": {},
   "source": [
    "We now split the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6f0b8f8-d43f-4a06-bed9-e6297dec6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fed442c4-8695-4c01-a089-4c05a267bf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06f48e4-9e22-4ea0-80e1-4563785ccd9f",
   "metadata": {},
   "source": [
    "## 3. Quantum kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ed186d6-4555-4801-9fc7-e847e1103e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_qubits = X_train.shape[1]\n",
    "n_qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e351460b-0264-495a-a3a4-6633c6060cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_kernel = qml.device(\"default.qubit\", wires=n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29ac81b1-e43e-4a3d-873b-73987d0128ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "projector = np.zeros((2**n_qubits, 2**n_qubits))\n",
    "projector[0, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66b80909-aa95-4419-a33a-c4d95c0de641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ece1ce01-0c3f-4e1b-a5f9-803e58371995",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev_kernel)\n",
    "def quantum_kernel(x1, x2):\n",
    "    AngleEmbedding(x1, wires=range(n_qubits))\n",
    "    qml.adjoint(AngleEmbedding)(x2, wires=range(n_qubits))\n",
    "    \n",
    "    return qml.expval(qml.Hermitian(projector, wires=range(n_qubits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92eae7ee-4315-4713-b71b-523108941151",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_circuit_input = (X_train[0], X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31dd242b-ff49-4d1f-ae22-3b4c70da554d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., requires_grad=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantum_kernel(*test_circuit_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bb111c-a8db-485c-8212-e8e6c4f32da8",
   "metadata": {},
   "source": [
    "We inspect our initial circuit a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a4fbaa5a-4553-4da3-a324-d13fa85808a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ─╭AngleEmbedding(M0)─╭AngleEmbedding(M0)†─┤ ╭<𝓗(M1)>\n",
      "1: ─├AngleEmbedding(M0)─├AngleEmbedding(M0)†─┤ ├<𝓗(M1)>\n",
      "2: ─├AngleEmbedding(M0)─├AngleEmbedding(M0)†─┤ ├<𝓗(M1)>\n",
      "3: ─╰AngleEmbedding(M0)─╰AngleEmbedding(M0)†─┤ ╰<𝓗(M1)>\n"
     ]
    }
   ],
   "source": [
    "print(qml.draw(quantum_kernel)(*test_circuit_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0cdf9df7-848c-4ca3-8f97-b97d2aa5b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs_func = qml.specs(quantum_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fce5db22-28d2-4f35-8772-3d51e935d04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gate_sizes': defaultdict(int, {4: 2}),\n",
       " 'gate_types': defaultdict(int,\n",
       "             {'AngleEmbedding': 1, 'Adjoint(AngleEmbedding)': 1}),\n",
       " 'num_operations': 2,\n",
       " 'num_observables': 1,\n",
       " 'num_diagonalizing_gates': 1,\n",
       " 'num_used_wires': 4,\n",
       " 'depth': 2,\n",
       " 'num_trainable_params': 0,\n",
       " 'num_device_wires': 4,\n",
       " 'device_name': 'default.qubit.autograd',\n",
       " 'expansion_strategy': 'gradient',\n",
       " 'gradient_options': {},\n",
       " 'interface': 'autograd',\n",
       " 'diff_method': 'best',\n",
       " 'gradient_fn': 'backprop'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs_func(*test_circuit_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d5a30-6e84-4f5e-817a-ce2003883062",
   "metadata": {},
   "source": [
    "# 4. SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f943a402-90f4-4b8a-8671-5430a4aaab62",
   "metadata": {},
   "source": [
    "We use the quantum kernel above to create a custom kernel for the scikit-learn `SVC` algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5519613b-2b01-472b-8778-bb80f1f52477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_kernel_matrix(X, Y):\n",
    "    \"\"\"Computes the value of `kernel_function(x, y)` for each pair of x \\in X, y \\in Y into a matrix\"\"\"\n",
    "    \n",
    "    return [[quantum_kernel(x, y) for y in Y] for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb67077a-2d40-4a6a-9010-205da08f9a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&lt;function custom_kernel_matrix at 0x7fa8511d1c60&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&lt;function custom_kernel_matrix at 0x7fa8511d1c60&gt;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel=<function custom_kernel_matrix at 0x7fa8511d1c60>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel=custom_kernel_matrix, decision_function_shape=\"ovr\")\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2dfef73-1a0c-4ec9-ad9a-6f825a8f43fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12545"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_kernel.num_executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d0006df-c393-4fd7-97e8-37b35f76e569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svc.predict(X_test)\n",
    "accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8121bbb3-c695-4027-a13a-a8d8778124d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16801"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_kernel.num_executions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a859d3-d805-46c7-8ce5-80cda4b17c53",
   "metadata": {},
   "source": [
    "For our initial quantum kernel that uses angle embedding for the input **(depth=2, n_qubits=4)**, we get a test accuracy of **0.9474** (to four decimal places). The next question is can we do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e2e678-749d-49cc-9d4f-ffbbd46eb8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
